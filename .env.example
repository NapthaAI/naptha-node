PRIVATE_KEY=

# Node
IN_DOCKER=true
GPU=true # set to true if gpu is available (Only for running node on docker)
DOCKER_JOBS=false
DEV_MODE=true

# Servers
NODE_TYPE=direct
NODE_IP=http://localhost
NODE_PORT=7001
NODE_ROUTING=ws://node.naptha.ai:8765
NUM_SERVERS=1

# MQ
RMQ_USER=username
RMQ_PASSWORD=password
CELERY_BROKER_URL=amqp://localhost:5672/

# LLMs
LLM_BACKEND=vllm # vllm or ollama
VLLM_MODEL=NousResearch/Hermes-3-Llama-3.1-8B # supports serving single model
OLLAMA_MODELS=phi # supports serving multiple models
OPENAI_API_KEY=sk-
STABILITY_API_KEY=sk-

# Local DB
SURREALDB_PORT=3002
DB_NS=naptha
DB_DB=naptha
DB_URL=ws://localhost:3002/rpc
DB_ROOT_USER=root
DB_ROOT_PASS=root

# Storage
BASE_OUTPUT_DIR=./storage/fs
MODULES_PATH=./storage/hub/modules
IPFS_GATEWAY_URL=/dns/provider.akash.pro/tcp/31832/http

# Hub
LOCAL_HUB=false
LOCAL_HUB_URL=ws://localhost:3001/rpc
PUBLIC_HUB_URL=ws://node.naptha.ai:3001/rpc
HUB_DB_PORT=3001
HUB_NS=naptha
HUB_DB=naptha
HUB_ROOT_USER=root
HUB_ROOT_PASS=root
HUB_USERNAME=seller1
HUB_PASSWORD=great-password
